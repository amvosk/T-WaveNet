{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285bb75d-0e06-42d2-8ad0-ba7b16bd073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn\n",
    "import einops\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa9e2ab-54c2-4c84-9f41-4d4817e0338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2863b977-c721-461a-a1d2-fec16694edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_hat, n_classes):\n",
    "    y_true_onehot = np.zeros((y_true.shape[0], n_classes))\n",
    "    y_true_onehot[np.arange(y_true.shape[0]), y_true] = 1\n",
    "    \n",
    "    y_hat_onehot = np.zeros((y_hat.shape[0], n_classes))\n",
    "    y_hat_onehot[np.arange(y_hat.shape[0]), y_hat] = 1\n",
    "    w = [np.mean(y_true==i) for i in range(n_classes)]\n",
    "\n",
    "    accuracy = np.mean(y_true == y_hat)\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_onehot[:, i], y_hat_onehot[:, i])\n",
    "\n",
    "    Fw, Fm = 0, 0\n",
    "    for i in range(n_classes):\n",
    "        prec = precision[i][1]\n",
    "        rec = recall[i][1]\n",
    "        Fw += 2 * w[i] * (prec * rec) / (prec + rec)\n",
    "        Fm += 2 * (prec * rec) / (prec + rec) / n_classes\n",
    "    return Fw, Fm, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca121e7-4e38-4539-aee0-2ef317b4a11a",
   "metadata": {},
   "source": [
    "## Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea69f14-f16e-4f50-bcca-b5993226fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFeatures(torch.nn.Module):\n",
    "    kernel_length = torch.tensor([7, 9, 11], dtype=torch.float)\n",
    "    weight = None\n",
    "    bias = None\n",
    "    dilation = None\n",
    "    padding = None\n",
    "    \n",
    "    def __init__(self, n_kernels, ts_length, n_ts, random_seed=0):\n",
    "        super(RandomFeatures, self).__init__()\n",
    "        \n",
    "        self.n_kernels = n_kernels\n",
    "        self.ts_length = ts_length\n",
    "        self.n_ts = n_ts\n",
    "        self.random_seed = random_seed * n_kernels\n",
    "        self.create_kernels(self.random_seed)\n",
    "        \n",
    "    def create_kernels(self, random_seed=0):\n",
    "        torch.manual_seed(random_seed)\n",
    "        kernel_length_indices = torch.multinomial(self.kernel_length, self.n_kernels, replacement=True)\n",
    "        kernel_lengths = self.kernel_length[kernel_length_indices].to(torch.long)\n",
    "        weight_distributions_ = [torch.normal(mean=0, std=1, size=(kernel_length,), dtype=torch.double) for kernel_length in kernel_lengths]\n",
    "        weight_distributions = [weight_distribution - weight_distribution.mean() for weight_distribution in weight_distributions_]\n",
    "        self.weight = [weight_distribution.unsqueeze(0).unsqueeze(0) for weight_distribution in weight_distributions]\n",
    "        \n",
    "        self.spatial_weight = torch.normal(mean=0, std=1, size=(self.n_kernels, self.n_ts), dtype=torch.double)\n",
    "        self.spatial_weight = self.spatial_weight / torch.linalg.vector_norm(self.spatial_weight, dim=1, keepdim=True)\n",
    "        \n",
    "        self.bias = torch.rand(size=(self.n_kernels,), dtype=torch.double).reshape(-1,1) * 2 - 1\n",
    "        A = math.log(self.ts_length-1) - torch.log(kernel_lengths-1)\n",
    "        s = torch.rand(size=(self.n_kernels,)) * A\n",
    "        self.dilation = torch.floor(2**s)\n",
    "        self.padding = ((self.dilation * (kernel_lengths-1) / 2) * torch.randint(2, size=(self.n_kernels,)))\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # x = einops.rearrange(x, 'b c t -> b 1 t')\n",
    "        features = torch.empty(size=(batch_size, self.n_kernels, 3))\n",
    "        \n",
    "        for i in range(self.n_kernels):\n",
    "            \n",
    "            ts_collapsed = torch.einsum('bct,c->bt', x, self.spatial_weight[i])\n",
    "            ts_collapsed = einops.rearrange(ts_collapsed, 'b t -> b 1 t')\n",
    "            # print(ts_collapsed.shape)\n",
    "            \n",
    "            ts_convolved = torch.nn.functional.conv1d(\n",
    "                ts_collapsed, weight=self.weight[i], bias=self.bias[i], \n",
    "                padding=int(self.padding[i].item()), dilation=int(self.dilation[i].item())\n",
    "            )\n",
    "            ts_convolved = ts_convolved.squeeze(1)\n",
    "\n",
    "            ts_convolved_max = torch.max(ts_convolved, dim=1).values\n",
    "            features[:,i,0] = ts_convolved_max\n",
    "\n",
    "            ts_convolved_ppv = torch.mean((ts_convolved > 0).to(torch.float), dim=1)\n",
    "            features[:,i,1] = ts_convolved_ppv\n",
    "            \n",
    "            ts_convolved_amp = torch.mean(torch.abs(ts_convolved), dim=1)\n",
    "            features[:,i,2] = ts_convolved_amp\n",
    "        \n",
    "        features = einops.rearrange(features, 'b s f -> b (s f)')\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc9767c-39ca-4675-a09c-035a09ee8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f05afc-c1cb-4177-b967-a946a3ad6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rocket():\n",
    "    def __init__(self, n_features, ts_length, n_ts, n_classes, random_seed=0):\n",
    "        self.n_classes = n_classes\n",
    "        self.random_seed = random_seed\n",
    "        self.batch_size = 1024\n",
    "        assert n_features % 3 == 0, 'n_features must be even'\n",
    "        n_kernels = n_features // 3\n",
    "        self.rf = RandomFeatures(n_kernels, ts_length, n_ts, random_seed)\n",
    "        self.csf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 20))\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        dataset = TimeSeriesDataset(X, Y)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "        \n",
    "        features, labels = [], []\n",
    "        for x, y in tqdm(dataloader):\n",
    "            features.append(self.rf(x).detach().cpu().numpy().astype(np.float32))\n",
    "            labels.append(y.detach().cpu().numpy())\n",
    "        features = np.concatenate(features, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0)\n",
    "        self.csf.fit(features, labels)\n",
    "\n",
    "    def predict(self, X, Y=None):\n",
    "        dataset = TimeSeriesDataset(X, Y)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False, generator=torch.Generator(device='cuda'))\n",
    "        \n",
    "        features = []\n",
    "        for x, _ in tqdm(dataloader):\n",
    "            features.append(self.rf(x).detach().cpu().numpy().astype(np.float32))\n",
    "        features = np.concatenate(features, axis=0)\n",
    "\n",
    "        Y_hat = self.csf.predict(features)\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a5fc3-932e-47c8-a616-8b5f35378c93",
   "metadata": {},
   "source": [
    "## UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "75e7f521-b4d1-4855-bc61-093c1552cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load = 'datasets/HAR/'\n",
    "train_x = np.load(path_load + 'train_x.npy')\n",
    "train_y = np.load(path_load + 'train_y.npy')\n",
    "test_x = np.load(path_load + 'test_x.npy')\n",
    "test_y = np.load(path_load + 'test_y.npy')\n",
    "\n",
    "ts_length = train_x.shape[2]\n",
    "n_ts = train_x.shape[1]\n",
    "n_classes = np.unique(train_y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b989e90e-8d21-4f3a-a4e4-d7809119461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 90000\n",
    "rocket = Rocket(n_features, ts_length, n_ts, n_classes, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6cd9744b-bd8d-45b4-9251-9ba79b828709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [23:24<00:00, 175.61s/it]\n"
     ]
    }
   ],
   "source": [
    "rocket.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb3cca46-a99e-42e5-85a4-2b4e1013cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:18<00:00, 186.04s/it]\n"
     ]
    }
   ],
   "source": [
    "test_y_hat = rocket.predict(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ce95ebf7-c8fd-476e-8fb3-a56e210613b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9717398821825951 0.9726660054194296 0.9718357651849339\n"
     ]
    }
   ],
   "source": [
    "Fw, Fm, accuracy = metrics(test_y, test_y_hat, n_classes)\n",
    "print(Fw, Fm, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60297e1c-d284-425e-8502-ac9e87de2560",
   "metadata": {},
   "source": [
    "## OPPOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e61e14fb-9017-458f-b8ca-0558ecfccd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load = 'datasets/OPPOR/'\n",
    "train_x = np.load(path_load + 'train_x.npy').astype(np.float64)\n",
    "train_y = np.load(path_load + 'train_y.npy')\n",
    "test_x = np.load(path_load + 'test_x.npy').astype(np.float64)\n",
    "test_y = np.load(path_load + 'test_y.npy')\n",
    "\n",
    "ts_length = train_x.shape[2]\n",
    "n_ts = train_x.shape[1]\n",
    "n_classes = np.unique(train_y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4083da47-d66a-489d-958a-8b284561cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 12000\n",
    "rocket = Rocket(n_features, ts_length, n_ts, n_classes, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "360ce18d-8d4a-40d2-b5dd-6bab6e5db48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [15:58<00:00, 28.18s/it]\n"
     ]
    }
   ],
   "source": [
    "rocket.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6acf98e3-a0ed-4772-87d1-d5c8f8e5953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:53<00:00, 27.58s/it]\n"
     ]
    }
   ],
   "source": [
    "test_y_hat = rocket.predict(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26219422-e341-4504-932d-f459a787255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5059436684850275 0.5070361930295703 0.5178185745140389\n"
     ]
    }
   ],
   "source": [
    "Fw, Fm, accuracy = metrics(test_y, test_y_hat, n_classes)\n",
    "print(Fw, Fm, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648eed6-6594-4bcf-a82d-9e35db3cb095",
   "metadata": {},
   "source": [
    "## NinaPro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea676f31-4db9-49c5-b314-86081abc238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load = 'datasets/NinaPro/'\n",
    "train_x = np.load(path_load + 'train_x.npy').astype(np.float64)\n",
    "train_y = np.load(path_load + 'train_y.npy')\n",
    "test_x = np.load(path_load + 'test_x.npy').astype(np.float64)\n",
    "test_y = np.load(path_load + 'test_y.npy')\n",
    "\n",
    "ts_length = train_x.shape[2]\n",
    "n_ts = train_x.shape[1]\n",
    "n_classes = np.unique(train_y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ac8e8f-56f7-41fd-bed6-13df12040c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 30000\n",
    "rocket = Rocket(n_features, ts_length, n_ts, n_classes, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657ce58-543b-461e-8fee-8ab08a97c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [40:11<00:00, 77.78s/it]\n"
     ]
    }
   ],
   "source": [
    "rocket.fit(train_x, train_y)\n",
    "del train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e783603-136f-41d7-9e65-52bbacf366d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_hat = rocket.predict(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98420e19-fd86-41c5-90be-88fcfcb3c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fw, Fm, accuracy = metrics(test_y, test_y_hat, n_classes)\n",
    "print(Fw, Fm, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26736928-5180-45d9-9cba-0a6388a26cb1",
   "metadata": {},
   "source": [
    "## BCICIV2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e550681-1ec5-4fc6-b5d3-5b6a64ec77bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [56:27<00:00, 27.99s/it]\n",
      "100%|██████████| 16/16 [07:30<00:00, 28.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28201840023953084 0.28184236783408734 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 86/121 [40:33<16:30, 28.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4500\u001b[39m\n\u001b[1;32m     15\u001b[0m rocket \u001b[38;5;241m=\u001b[39m Rocket(n_features, ts_length, n_ts, n_classes, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mrocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_x, train_y\n\u001b[1;32m     18\u001b[0m test_y_hat \u001b[38;5;241m=\u001b[39m rocket\u001b[38;5;241m.\u001b[39mpredict(test_x, test_y)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mRocket.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     15\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m---> 17\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     18\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(y\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     19\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(features, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mRandomFeatures.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m ts_collapsed \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(ts_collapsed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb t -> b 1 t\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print(ts_collapsed.shape)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m ts_convolved \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m     47\u001b[0m     ts_collapsed, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[i], bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i], \n\u001b[0;32m---> 48\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m), dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation[i]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m ts_convolved \u001b[38;5;241m=\u001b[39m ts_convolved\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m ts_convolved_max \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(ts_convolved, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Fws, Fms, accuracys = [], [], []\n",
    "\n",
    "for i in range(9):\n",
    "    path_load = f'datasets/BCICIV2a/subject_left_{i}/'\n",
    "    train_x = np.load(path_load + 'train_x.npy').astype(np.float64)\n",
    "    train_y = np.load(path_load + 'train_y.npy')\n",
    "    test_x = np.load(path_load + 'test_x.npy').astype(np.float64)\n",
    "    test_y = np.load(path_load + 'test_y.npy')\n",
    "\n",
    "    ts_length = train_x.shape[2]\n",
    "    n_ts = train_x.shape[1]\n",
    "    n_classes = np.unique(train_y).shape[0]\n",
    "\n",
    "    n_features = 4500\n",
    "    rocket = Rocket(n_features, ts_length, n_ts, n_classes, random_seed=0)\n",
    "    rocket.fit(train_x, train_y)\n",
    "    del train_x, train_y\n",
    "    test_y_hat = rocket.predict(test_x, test_y)\n",
    "    Fw, Fm, accuracy = metrics(test_y, test_y_hat, n_classes)\n",
    "    print(Fw, Fm, accuracy)\n",
    "    del rocket\n",
    "\n",
    "    Fws.append(Fw)\n",
    "    Fms.append(Fm)\n",
    "    accuracys.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388d758-15ec-4620-a088-511275633c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Fws), np.mean(Fms), np.mean(accuracys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f2a87-6748-4759-a27e-521827f23997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6918e-e771-4603-888b-408fda81357a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
